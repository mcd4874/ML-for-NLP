{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import classification_report, confusion_matrix,log_loss, accuracy_score\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "import nltk\n",
    "import gensim\n",
    "import os\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>sentence</th>\n",
       "      <th>polarity</th>\n",
       "      <th>issue</th>\n",
       "      <th>genre</th>\n",
       "      <th>uname</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>This is definitely a must have if your state d...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>GENRE_B</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>It's a great place and I highly recommend it.</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>GENRE_B</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>I will see the doctors, take some blood tests ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>GOING_TO_PLACES</td>\n",
       "      <td>GENRE_A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>I can tell you about having my phone and elect...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>MONEY_ISSUE</td>\n",
       "      <td>GENRE_A</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>Their steaks are 100% recommended!</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>GENRE_B</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index                                           sentence  polarity  \\\n",
       "0      0  This is definitely a must have if your state d...  POSITIVE   \n",
       "1      1      It's a great place and I highly recommend it.  POSITIVE   \n",
       "2      2  I will see the doctors, take some blood tests ...   NEUTRAL   \n",
       "3      3  I can tell you about having my phone and elect...  NEGATIVE   \n",
       "4      4                 Their steaks are 100% recommended!  POSITIVE   \n",
       "\n",
       "             issue    genre  uname  \n",
       "0             NONE  GENRE_B    NaN  \n",
       "1             NONE  GENRE_B    NaN  \n",
       "2  GOING_TO_PLACES  GENRE_A    NaN  \n",
       "3      MONEY_ISSUE  GENRE_A    NaN  \n",
       "4             NONE  GENRE_B    NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('PS3_training_data.txt',  delimiter='\t', names = [\"index\",\"sentence\",\"polarity\",\"issue\",\"genre\", \"uname\"])\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>polarity</th>\n",
       "      <th>issue</th>\n",
       "      <th>genre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This is definitely a must have if your state d...</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>GENRE_B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>It's a great place and I highly recommend it.</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>GENRE_B</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>I will see the doctors, take some blood tests ...</td>\n",
       "      <td>NEUTRAL</td>\n",
       "      <td>GOING_TO_PLACES</td>\n",
       "      <td>GENRE_A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I can tell you about having my phone and elect...</td>\n",
       "      <td>NEGATIVE</td>\n",
       "      <td>MONEY_ISSUE</td>\n",
       "      <td>GENRE_A</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Their steaks are 100% recommended!</td>\n",
       "      <td>POSITIVE</td>\n",
       "      <td>NONE</td>\n",
       "      <td>GENRE_B</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  polarity  \\\n",
       "0  This is definitely a must have if your state d...  POSITIVE   \n",
       "1      It's a great place and I highly recommend it.  POSITIVE   \n",
       "2  I will see the doctors, take some blood tests ...   NEUTRAL   \n",
       "3  I can tell you about having my phone and elect...  NEGATIVE   \n",
       "4                 Their steaks are 100% recommended!  POSITIVE   \n",
       "\n",
       "             issue    genre  \n",
       "0             NONE  GENRE_B  \n",
       "1             NONE  GENRE_B  \n",
       "2  GOING_TO_PLACES  GENRE_A  \n",
       "3      MONEY_ISSUE  GENRE_A  \n",
       "4             NONE  GENRE_B  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = data[[\"sentence\",\"polarity\",\"issue\",\"genre\"]]\n",
    "# hist = data.hist(bin = 3)\n",
    "data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " POS : % , NEG : %, NEU : % (0.41953125, 0.50078125, 0.0796875)\n"
     ]
    }
   ],
   "source": [
    "POS = len(data[data.polarity == \"POSITIVE\"])\n",
    "NEG = len(data[data.polarity == \"NEGATIVE\"])\n",
    "NEU = len(data[data.polarity == \"NEUTRAL\"])\n",
    "total = len(data)\n",
    "print(\" POS : % , NEG : %, NEU : %\",(POS/total,NEG/total,NEU/total))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MySentences(object):\n",
    "#     \"\"\"MySentences is a generator to produce a list of tokenized sentences \n",
    "    \n",
    "#     Takes a list of numpy arrays containing documents.\n",
    "    \n",
    "#     Args:\n",
    "#         arrays: List of arrays, where each element in the array contains a document.\n",
    "#     \"\"\"\n",
    "#     def __init__(self, *arrays):\n",
    "#         self.arrays = arrays\n",
    " \n",
    "#     def __iter__(self):\n",
    "#         for array in self.arrays:\n",
    "#             for document in array:\n",
    "#                 for sent in nltk.sent_tokenize(document):\n",
    "#                     yield nltk.word_tokenize(sent)\n",
    "\n",
    "# def get_word2vec(sentences, location,retrain):\n",
    "#     \"\"\"Returns trained word2vec\n",
    "    \n",
    "#     Args:\n",
    "#         sentences: iterator for sentences\n",
    "        \n",
    "#         location (str): Path to save/load word2vec\n",
    "#     \"\"\"\n",
    "#     if os.path.exists(location) and not retrain :\n",
    "#         print('Found {}'.format(location))\n",
    "#         model = gensim.models.Word2Vec.load(location)\n",
    "#         return model\n",
    "    \n",
    "#     print('{} not found. training model'.format(location))\n",
    "#     model = gensim.models.Word2Vec(sentences, size=100, window=5, min_count=5, workers=4)\n",
    "#     print('Model done training. Saving to disk')\n",
    "#     model.save(location)\n",
    "#     return model\n",
    "\n",
    "# corpus_train = data[\"sentence\"]\n",
    "# w2vec = get_word2vec(\n",
    "#     MySentences(\n",
    "#        corpus_train\n",
    "#     ),\n",
    "#     'w2vmodel.model',\n",
    "#     False\n",
    "# )\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class MyTokenizer:\n",
    "#     def __init__(self):\n",
    "#         pass\n",
    "    \n",
    "#     def fit(self, X, y=None):\n",
    "#         return self\n",
    "    \n",
    "#     def transform(self, X):\n",
    "#         transformed_X = []\n",
    "#         for document in X:\n",
    "#             tokenized_doc = []\n",
    "#             for sent in nltk.sent_tokenize(document):\n",
    "#                 tokenized_doc += nltk.word_tokenize(sent)\n",
    "#             transformed_X.append(np.array(tokenized_doc))\n",
    "#         return np.array(transformed_X)\n",
    "    \n",
    "#     def fit_transform(self, X, y=None):\n",
    "#         return self.transform(X)\n",
    "\n",
    "# class MeanEmbeddingVectorizer(object):\n",
    "#     def __init__(self, word2vec):\n",
    "#         self.word2vec = word2vec\n",
    "#         # if a text is empty we should return a vector of zeros\n",
    "#         # with the same dimensionality as all the other vectors\n",
    "#         self.dim = len(word2vec.wv.syn0[0])\n",
    "\n",
    "#     def fit(self, X, y=None):\n",
    "#         return self\n",
    "\n",
    "#     def transform(self, X):\n",
    "#         X = MyTokenizer().fit_transform(X)\n",
    "        \n",
    "#         return np.array([\n",
    "#             np.mean([self.word2vec.wv[w] for w in words if w in self.word2vec.wv]\n",
    "#                     or [np.zeros(self.dim)], axis=0)\n",
    "#             for words in X\n",
    "#         ])\n",
    "    \n",
    "#     def fit_transform(self, X, y=None):\n",
    "#         return self.transform(X)\n",
    "    \n",
    "# mean_embedding_vectorizer = MeanEmbeddingVectorizer(w2vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cv = CountVectorizer().fit(data[\"sentence\"])\n",
    "df_train,df_test = train_test_split(data,test_size=0.2, random_state=35)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = mean_embedding_vectorizer.fit_transform(df_train['sentence'])\n",
    "# y_train = df_train['polarity']\n",
    "# x_test = mean_embedding_vectorizer.fit_transform(df_test['sentence'])\n",
    "# y_test = df_test['polarity']\n",
    "# print((x_train.shape,y_train.shape))\n",
    "# ros = RandomOverSampler(random_state=42)\n",
    "# x_train,y_train =  ros.fit_resample(x_train,y_train)\n",
    "# print((x_train.shape,y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "((2048, 6689), (2048,))\n",
      "((3078, 6689), (3078,))\n"
     ]
    }
   ],
   "source": [
    "x_train = cv.transform(df_train['sentence'])\n",
    "y_train = df_train['polarity']\n",
    "x_test = cv.transform(df_test['sentence'])\n",
    "y_test = df_test['polarity']\n",
    "print((x_train.shape,y_train.shape))\n",
    "ros = RandomOverSampler(random_state=42)\n",
    "x_train,y_train =  ros.fit_resample(x_train,y_train)\n",
    "print((x_train.shape,y_train.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=2, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=None,\n",
       "            oob_score=False, random_state=0, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = RandomForestClassifier(n_estimators=100, max_depth=2,random_state=0)\n",
    "model.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(512,)\n",
      "(512,)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "predict = model.predict(x_test)\n",
    "print(predict.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5859375\n"
     ]
    }
   ],
   "source": [
    "print(accuracy_score(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    NEGATIVE       0.69      0.56      0.62       256\n",
      "     NEUTRAL       0.30      0.51      0.38        47\n",
      "    POSITIVE       0.59      0.63      0.61       209\n",
      "\n",
      "   micro avg       0.59      0.59      0.59       512\n",
      "   macro avg       0.53      0.57      0.54       512\n",
      "weighted avg       0.61      0.59      0.59       512\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[231   0  25]\n",
      " [ 46   0   1]\n",
      " [180   0  29]]\n"
     ]
    }
   ],
   "source": [
    "print(confusion_matrix(y_test, predict))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
